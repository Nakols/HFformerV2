{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.metrics import f1_score, precision_recall_fscore_support, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labelizer(true, pred):\n",
    "    true_trinary, pred_trinary = true.copy(), pred.copy()\n",
    "    true_trinary[true_trinary>0], pred_trinary[pred_trinary>0] = 1, 1\n",
    "    true_trinary[true_trinary<=0],  pred_trinary[pred_trinary<=0] = -1, -1\n",
    "    return true_trinary, pred_trinary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetaLoader(Dataset):\n",
    "    '''\n",
    "    Class for loading data in the meta-labelling model.\n",
    "    '''\n",
    "    def __init__(self, df, forecast_history, forecast_length, start_stamp=0, end_stamp=None, LAG=0):\n",
    "        super().__init__()\n",
    "        self.forecast_history = forecast_history\n",
    "        self.forecast_length = forecast_length\n",
    "        self.LAG = LAG\n",
    "        self.df = df.copy()\n",
    "        if start_stamp != 0 and end_stamp is not None:\n",
    "            if self.LAG == 0:\n",
    "                self.df = self.df[start_stamp:end_stamp]\n",
    "            else:\n",
    "                self.df = self.df[start_stamp:end_stamp+self.LAG]\n",
    "        elif start_stamp != 0:\n",
    "            self.df = self.df[start_stamp:]\n",
    "        elif end_stamp is not None:\n",
    "            if self.LAG == 0:\n",
    "                self.df = self.df[:end_stamp]\n",
    "            else:\n",
    "                self.df = self.df[:end_stamp+self.LAG]\n",
    "        if (len(self.df) - self.df.count()).max() != 0:\n",
    "            print('Missing values in data.')\n",
    "            print(len(self.df) - self.df.count())\n",
    "        self.counter = 0\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        rows = self.df.iloc[idx: self.forecast_history + idx].copy().to_numpy()\n",
    "        epsilon = 0.0001\n",
    "        targs_idx_start = self.forecast_history + idx\n",
    "        future_return = 0\n",
    "        if self.LAG == 0:\n",
    "            targ_rows = self.df.iloc[targs_idx_start: self.forecast_length + targs_idx_start].copy().to_numpy()\n",
    "        else:\n",
    "            future_prices = self.df.iloc[targs_idx_start + self.LAG - 1: targs_idx_start + self.LAG].copy().to_numpy()\n",
    "            future_return = np.log(future_prices[0,1]/rows[-1:,1])*10_000\n",
    "        src_data = rows\n",
    "        src_std = np.std(src_data, axis = 0)+epsilon\n",
    "        src_median = np.mean(src_data, axis = 0)\n",
    "        src_std, src_median = src_std.flatten(), src_median.flatten()\n",
    "        src_data_medianized = torch.from_numpy((src_data-src_median)/src_std).float()\n",
    "        future_return_trinary = np.array([0,0,1]) if future_return > 0 else np.array([1,0,0]) if future_return < 0 else np.array([0,1,0])\n",
    "        return src_data_medianized, future_return_trinary, src_data\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.LAG == 0:\n",
    "            return (len(self.df) - self.forecast_history - self.forecast_length - 1)\n",
    "        else:\n",
    "            return (len(self.df) - self.forecast_history - self.LAG - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Meta(torch.nn.Module):\n",
    "    '''\n",
    "    Meta-labelling model\n",
    "    '''\n",
    "    def __init__(self, input_size, d_model, output_size):\n",
    "        super(Meta, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_size, d_model)\n",
    "        self.activation1 = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(d_model, output_size)\n",
    "        self.activation2 = nn.Softmax()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.linear1(x)\n",
    "        out = self.activation1(out)\n",
    "        out = out[:,0,:]\n",
    "        out = self.linear2(out)\n",
    "        out = self.activation2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "orderbook = pd.read_csv('./input_data/all/orderbook.csv')\n",
    "orderbook['price'] = orderbook['w_midprice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./results_HFformer/1658424401_list_results.pkl', 'rb') as f:\n",
    "    predictions_hfformer = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_returns, true_returns = predictions_hfformer[19][0], predictions_hfformer[19][1]\n",
    "true_trinary, pred_trinary = labelizer(true_returns, pred_returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.64033568, 0.62742576]),\n",
       " array([0.64495063, 0.62271627]),\n",
       " array([0.64263487, 0.62506215]),\n",
       " array([101983,  97921]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_recall_fscore_support(true_trinary, pred_trinary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "orderbook = orderbook[2_000_000:2_000_000+len(pred_returns)]\n",
    "orderbook['predicted_return'] = pred_trinary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_trade_data(df, lag, forecast_window=None):\n",
    "    if forecast_window:\n",
    "        df['lag_return'] = np.log(df['price'].shift(forecast_window)/df['price'].shift(forecast_window+1))\n",
    "        return df.iloc[forecast_window+1:,:]\n",
    "    if lag == 0:\n",
    "        return df\n",
    "    else:\n",
    "        col_name = 'log_lag'+str(lag)+'_price'\n",
    "        df[col_name] = np.log(df.price) - np.log(df.price).shift(lag)\n",
    "        return df.iloc[lag:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_history = 400\n",
    "forecast_window = 30\n",
    "epochs = 20\n",
    "batch_size = 64\n",
    "shuffle = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "trade = augment_trade_data(orderbook, lag=0, forecast_window=forecast_window)\n",
    "\n",
    "features = ['predicted_return',\n",
    "            'price', 'lag_return',\n",
    "            'bid1', 'bidqty1', 'bid2', 'bidqty2', 'bid3', 'bidqty3', 'bid4', 'bidqty4', 'bid5', 'bidqty5',\n",
    "            'bid6', 'bidqty6', 'bid7', 'bidqty7', 'bid8', 'bidqty8', 'bid9', 'bidqty9',\n",
    "            'ask1', 'askqty1', 'ask2', 'askqty2', 'ask3', 'askqty3', 'ask4', 'askqty4', 'ask5', 'askqty5',\n",
    "            'ask6', 'askqty6', 'ask7', 'askqty7', 'ask8', 'askqty8', 'ask9', 'askqty9']\n",
    "\n",
    "train_set = MetaLoader(df=trade[features], forecast_history=forecast_history, forecast_length=1,\n",
    "                          start_stamp=0, end_stamp=10_000, LAG=2)\n",
    "\n",
    "val_set = MetaLoader(df=trade[features], forecast_history=forecast_history, forecast_length=1,\n",
    "                          start_stamp=0, end_stamp=10_000, LAG=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Meta(39, 16, 3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adamax(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wh/v19kyh554sxg44m620vsh05c0000gn/T/ipykernel_16276/2426879783.py:14: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  out = self.activation2(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4594    0  223]\n",
      " [   2    0    0]\n",
      " [4522    0  258]]\n",
      "| epoch: 1 | train loss: 0.9850111603736877 | val loss: 144.4152673482895 | f1 score: 0.2524757269844349 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wh/v19kyh554sxg44m620vsh05c0000gn/T/ipykernel_16276/2426879783.py:14: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  out = self.activation2(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4588    0  229]\n",
      " [   2    0    0]\n",
      " [4509    0  271]]\n",
      "| epoch: 2 | train loss: 0.983620822429657 | val loss: 144.27565652132034 | f1 score: 0.2540121319547879 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wh/v19kyh554sxg44m620vsh05c0000gn/T/ipykernel_16276/2426879783.py:14: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  out = self.activation2(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4577    0  240]\n",
      " [   2    0    0]\n",
      " [4472    0  308]]\n",
      "| epoch: 3 | train loss: 0.9817782640457153 | val loss: 144.17260360717773 | f1 score: 0.2585654590269531 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wh/v19kyh554sxg44m620vsh05c0000gn/T/ipykernel_16276/2426879783.py:14: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  out = self.activation2(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4529    0  288]\n",
      " [   2    0    0]\n",
      " [4435    0  345]]\n",
      "| epoch: 4 | train loss: 0.9808297157287598 | val loss: 144.11379289627075 | f1 score: 0.26155243080357155 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wh/v19kyh554sxg44m620vsh05c0000gn/T/ipykernel_16276/2426879783.py:14: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  out = self.activation2(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4489    0  328]\n",
      " [   2    0    0]\n",
      " [4358    0  422]]\n",
      "| epoch: 5 | train loss: 0.9792852997779846 | val loss: 144.02448111772537 | f1 score: 0.2698603125085182 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wh/v19kyh554sxg44m620vsh05c0000gn/T/ipykernel_16276/2426879783.py:14: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  out = self.activation2(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4452    0  365]\n",
      " [   1    0    1]\n",
      " [4318    0  462]]\n",
      "| epoch: 6 | train loss: 0.9778462052345276 | val loss: 143.96687304973602 | f1 score: 0.27334956538390637 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wh/v19kyh554sxg44m620vsh05c0000gn/T/ipykernel_16276/2426879783.py:14: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  out = self.activation2(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4399    0  418]\n",
      " [   1    0    1]\n",
      " [4238    0  542]]\n",
      "| epoch: 7 | train loss: 0.9763882160186768 | val loss: 143.89722138643265 | f1 score: 0.2809001979908427 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wh/v19kyh554sxg44m620vsh05c0000gn/T/ipykernel_16276/2426879783.py:14: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  out = self.activation2(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4285    0  532]\n",
      " [   1    0    1]\n",
      " [4059    0  721]]\n",
      "| epoch: 8 | train loss: 0.9755994081497192 | val loss: 143.76732003688812 | f1 score: 0.2966986566239284 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wh/v19kyh554sxg44m620vsh05c0000gn/T/ipykernel_16276/2426879783.py:14: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  out = self.activation2(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4252    0  565]\n",
      " [   1    0    1]\n",
      " [4024    0  756]]\n",
      "| epoch: 9 | train loss: 0.9756187200546265 | val loss: 143.7134144306183 | f1 score: 0.2990817925118713 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wh/v19kyh554sxg44m620vsh05c0000gn/T/ipykernel_16276/2426879783.py:14: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  out = self.activation2(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4171    0  646]\n",
      " [   1    0    1]\n",
      " [3942    0  838]]\n",
      "| epoch: 10 | train loss: 0.9740628004074097 | val loss: 143.62005281448364 | f1 score: 0.3042114479601546 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wh/v19kyh554sxg44m620vsh05c0000gn/T/ipykernel_16276/2426879783.py:14: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  out = self.activation2(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4175    0  642]\n",
      " [   1    0    1]\n",
      " [3923    0  857]]\n",
      "| epoch: 11 | train loss: 0.9741186499595642 | val loss: 143.57824009656906 | f1 score: 0.30647163872522043 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wh/v19kyh554sxg44m620vsh05c0000gn/T/ipykernel_16276/2426879783.py:14: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  out = self.activation2(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3983    0  834]\n",
      " [   1    0    1]\n",
      " [3669    0 1111]]\n",
      "| epoch: 12 | train loss: 0.9752256870269775 | val loss: 143.4572075009346 | f1 score: 0.3230576497877789 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wh/v19kyh554sxg44m620vsh05c0000gn/T/ipykernel_16276/2426879783.py:14: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  out = self.activation2(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3968    0  849]\n",
      " [   1    0    1]\n",
      " [3631    0 1149]]\n",
      "| epoch: 13 | train loss: 0.9732086062431335 | val loss: 143.35918962955475 | f1 score: 0.32603727774896674 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wh/v19kyh554sxg44m620vsh05c0000gn/T/ipykernel_16276/2426879783.py:14: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  out = self.activation2(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3837    0  980]\n",
      " [   1    0    1]\n",
      " [3487    0 1293]]\n",
      "| epoch: 14 | train loss: 0.9715458154678345 | val loss: 143.2275237441063 | f1 score: 0.3328738647299836 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wh/v19kyh554sxg44m620vsh05c0000gn/T/ipykernel_16276/2426879783.py:14: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  out = self.activation2(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3816    0 1001]\n",
      " [   1    0    1]\n",
      " [3447    0 1333]]\n",
      "| epoch: 15 | train loss: 0.9723817110061646 | val loss: 143.18185472488403 | f1 score: 0.33547903955631414 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wh/v19kyh554sxg44m620vsh05c0000gn/T/ipykernel_16276/2426879783.py:14: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  out = self.activation2(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3778    0 1039]\n",
      " [   1    0    1]\n",
      " [3391    0 1389]]\n",
      "| epoch: 16 | train loss: 0.9709256291389465 | val loss: 143.0759425163269 | f1 score: 0.3385670630397986 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wh/v19kyh554sxg44m620vsh05c0000gn/T/ipykernel_16276/2426879783.py:14: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  out = self.activation2(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3773    0 1044]\n",
      " [   1    0    1]\n",
      " [3383    0 1397]]\n",
      "| epoch: 17 | train loss: 0.9709489941596985 | val loss: 143.02171349525452 | f1 score: 0.33902406874946794 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wh/v19kyh554sxg44m620vsh05c0000gn/T/ipykernel_16276/2426879783.py:14: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  out = self.activation2(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3726    0 1091]\n",
      " [   1    0    1]\n",
      " [3318    0 1462]]\n",
      "| epoch: 18 | train loss: 0.9704731702804565 | val loss: 142.9431659579277 | f1 score: 0.34230520359647265 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wh/v19kyh554sxg44m620vsh05c0000gn/T/ipykernel_16276/2426879783.py:14: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  out = self.activation2(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3725    0 1092]\n",
      " [   2    0    0]\n",
      " [3324    0 1456]]\n",
      "| epoch: 19 | train loss: 0.9726157784461975 | val loss: 142.91895043849945 | f1 score: 0.3417061230056581 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wh/v19kyh554sxg44m620vsh05c0000gn/T/ipykernel_16276/2426879783.py:14: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  out = self.activation2(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3690    0 1127]\n",
      " [   2    0    0]\n",
      " [3258    0 1522]]\n",
      "| epoch: 20 | train loss: 0.9731727242469788 | val loss: 142.74199426174164 | f1 score: 0.34564109731630555 |\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=shuffle, sampler=None, batch_sampler=None, num_workers=0)\n",
    "val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=shuffle, sampler=None, batch_sampler=None, num_workers=0)\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    \n",
    "    output_all = torch.Tensor(0)\n",
    "    trg_all = torch.Tensor(0)\n",
    "    model1_pred = torch.Tensor(0)\n",
    "    \n",
    "    train_loss = 0\n",
    "    model.train()\n",
    "    for src, trg, src_data in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(src)\n",
    "        loss = criterion(output, trg.float())\n",
    "        train_loss =+ loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    val_loss = 0\n",
    "    model.eval()\n",
    "    for src, trg, src_data in val_loader:\n",
    "        output = model(src)\n",
    "        \n",
    "        output_all = torch.cat((output_all, output))\n",
    "        trg_all = torch.cat((trg_all, trg))\n",
    "        \n",
    "        loss = criterion(output, trg.float())\n",
    "        val_loss += loss.item()\n",
    "    \n",
    "    output_all = output_all.cpu().detach().numpy()\n",
    "    trg_all = trg_all.cpu().detach().numpy()\n",
    "    \n",
    "    output_all_trinary = np.zeros_like(output_all)\n",
    "    output_all_trinary[np.arange(len(output_all)), output_all.argmax(1)] = 1\n",
    "    \n",
    "    diff = np.abs(trg_all-output_all_trinary)\n",
    "    diff_sum = np.sum(diff, axis=1)\n",
    "    correct_actions = len(diff_sum[np.where(diff_sum==0)])\n",
    "             \n",
    "    f1 = f1_score(trg_all, output_all_trinary, average='macro')\n",
    "    print(confusion_matrix(trg_all.argmax(axis=1), output_all_trinary.argmax(axis=1)))\n",
    "    \n",
    "    #Determine same matches between model1 and model2\n",
    "    \n",
    "    \n",
    "    print(f'| epoch: {epoch} | train loss: {train_loss} | val loss: {val_loss} | f1 score: {f1} |')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3690,    0, 1127],\n",
       "       [   2,    0,    0],\n",
       "       [3258,    0, 1522]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(trg_all.argmax(axis=1), output_all_trinary.argmax(axis=1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
